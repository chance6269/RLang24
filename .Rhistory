group_by(job) %>%
summarise(mean_income=mean(income))
# 직업별 월급 평균표 만들기
# group_by(job), summarise(mean_income=)
job_income <- welfare %>%
filter(!is.na(job) & !is.na(income)) %>%
group_by(job) %>%
summarise(mean_income=mean(income))
head(job_income)
job_income %>%
arrange(-mean_income) %>%
head
job_income %>%
arrange(-mean_income) %>%
head(10)
ggplot(data = top10, aes(x= reorder(job, mean_income),y=mean_income)) +
geom_col() +
coord_flip()
top10 <- job_income %>%
arrange(-mean_income) %>%
head(10)
ggplot(data = top10, aes(x= reorder(job, mean_income),y=mean_income)) +
geom_col() +
coord_flip()
bottom10 <- job_income %>%
arrange(mean_income) %>%
head(10)
bottom10
ggplot(data = bottom10, aes(x= reorder(job, -mean_income),y=mean_income)) +
geom_col() +
coord_flip() + # 오른쪽으로 90도 회전
ylim(0, 850)
# 상관행렬 히트맵 만들기
head(mtcars)
car_cor <- cor(mtcars) # 상관행렬 생성
round(car_col, 2) # 소수점 셋째 자리에서 반올리
round(car_cor, 2) # 소수점 셋째 자리에서 반올림
install.packages("corrplot")
library(corrplot)
corrplot(car_cor)
corplot(car_cor, method = 'number')
corrplot(car_cor, method = 'number')
col <- colorRampPalette("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA")
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(car_cor,
method = "color", # 색깔로 표현
col = col(200), # 색상 200개 선정
type = 'lower', # 왼쪽 아래 행렬만 표시
order = 'hclust', # 유사한 상관계수끼리 군집화
addCoef.col = 'black', # 상관계수 색깔
tl.col = 'black', # 변수명 색깔
tl.srt = 45, # 변수명 45도 기울임
diag = F) # 대각 행렬 제외
head(10)
# 성별 직업 빈도표 만들기
job_male <- welfare %>%
filter(!is.na(job) & sex == 'male') %>%
group_by(job) %>%
summarise(n = n()) %>%
arrange(desc(n)) %>%
head(10)
job_male
job_female <- welfare %>%
filter(!is.na(job) & sex == 'female') %>%
group_by(job) %>%
summarise(n = n()) %>%
arrange(desc(n)) %>%
head(10)
job_female
job_male
# 그래프 만들기 ggplot
# 남성 직업 빈도 상위 10개 직업
ggplot(data = job_male, aes(x=reorder(job, n), y = n))+
geom_col() +
coord_flip()
# 여성 직업 빈도 상위 10개 직업
ggplot(data = job_female, aes(x=reorder(job, n), y = n))+
geom_col() +
coord_flip()
# 종교, 혼인 상태 전처리
class(welfare$religion)
table(welfare$religion)
welfare$religion <- ifelse(welfare$religion==1, 'yes', 'no')
table(welfare$religion)
qplot(welfare$religion)
class(welfare$marriage)
class(welfare$marriage)
table(welfare$marriage)
# 파생변수 만들기 이혼 여부
welfare$group_marriage <- ifelse(welfare$marriage==1,"marriage",
ifelse(welfare$marriage==3,"divorce",NA))
table(welfare$group_marriage)
table(is.na(welfare$group_marriage))
qplot(welfare$group_marriage)
# 종교 유무에 따른 이혼율 표
# group_by, summarise
religion_divorce <- welfare %>%
filter(!is.na(group_marriage)) %>%
group_by(religion, group_marriage) %>%
summarise(n = n()) %>%
mutate(tot_group = sum(n),
pct = round(n/tot_group*100, 1))
# 종교 유무에 따른 이혼율 표
# group_by, summarise
religion_marriage <- welfare %>%
filter(!is.na(group_marriage)) %>%
group_by(religion, group_marriage) %>%
summarise(n = n()) %>%
mutate(tot_group = sum(n),
pct = round(n/tot_group*100, 1))
religion_marriage
# 이혼 추출
divorce <- religion_marriage %>%
filter(group_marriage == 'divorce') %>%
select(religion,pct)
divorce
#  그래프 만들기
ggplot(data = divorce, aes(x = religion, y = pct)) +geom_col()
ageg_marriage <- welfare %>%
filter(!is.na(group_marriage)) %>%
group_by(ageg,group_marriage) %>%
summarise(n=n())
ageg_marriage
ageg_marriage <- welfare %>%
filter(!is.na(group_marriage)) %>%
group_by(ageg,group_marriage) %>%
summarise(n=n()) %>%
mutate(tot_group = sum(n),
pct = round(n/tot_group*100, 1))
ageg_marriage
ageg_divorce <- ageg_marriage %>%
filter(ageg!='young') %>%
select(ageg,pct)
ageg_divorce
ageg_divorce <- ageg_marriage %>%
filter(ageg!='young' & group_marriage=='divorce') %>%
select(ageg,pct)
ageg_divorce
ggplot(data=ageg_divorce, aes(x=ageg,y=pct)) + geom_col
ggplot(data=ageg_divorce, aes(x=ageg,y=pct)) + geom_col()
pct = round(n/tot_group*100,1)
ageg_religion_marriage <- welfare %>%
ageg_religion_marriage <- welfare %>%
ageg_religion_marriage <- welfare %>%
filter(!is.na(group_marriage) & ageg != 'young') %>%
group_by(ageg, religion, group_marriage) %>%
summarise(n=n()) %>%
mutate(tot_group = sum(n),
pct = round(n/tot_group*100,1))
ageg_religion_marriage <- welfare %>%
filter(!is.na(group_marriage) & ageg != 'young') %>%
group_by(ageg, religion, group_marriage) %>%
summarise(n=n()) %>%
mutate(tot_group = sum(n),
pct = round(n/tot_group*100,1))
ageg_religion_marriage
df_divorce <- ageg_religion_marriage %>%
filter(group_marriage=='divorce') %>%
select(ageg, religion, pct)
df_divorce
# 4. 연령대 및 종교 유무에 따른 이혼율 그래프 만들기
ggplot(data = df_divorce, aes(x=ageg, y=pct, fill = religion)) +
geom_col()
# 4. 연령대 및 종교 유무에 따른 이혼율 그래프 만들기
ggplot(data = df_divorce, aes(x=ageg, y=pct, fill = religion)) +
geom_col(position='dodge')
# 지역 변수 검토 및 전처리
class(welfare$code_region)
table(welfare$code_region)
# 2. 전처리
# 지역 코드 목록 만들기, welfare에 지역명 변수 추가하기
list_region <- dafta.frame(code_region = c(1:7),
region = c("서울",
"수도권(인천/경기)",
"부산/경남/울산",
"대구/경북",
"대전/충남",
"강원/충북",
"광주/전남/전북/제주"))
# 2. 전처리
# 지역 코드 목록 만들기, welfare에 지역명 변수 추가하기
list_region <- data.frame(code_region = c(1:7),
region = c("서울",
"수도권(인천/경기)",
"부산/경남/울산",
"대구/경북",
"대전/충남",
"강원/충북",
"광주/전남/전북/제주"))
list_region
welfare <- left_join(welfare, list_region, by='code_region')
welfare %>%
select(code_region, region) %>%
head
# 지역별 연령대 비율 분석하기
# 1. 지역별 연령대 비율표 만들기
# group_by(region, ageg)
region_ageg <- welfare %>%
group_by(region, ageg) %>%
summarise(n=n()) %>%
mutate(tot_group=sum(n),
pct = round(n/tot_group*100,1))
region_ageg
# 2. 그래프 만들기
# 연령대 비율 막대를 서로 다른 색으로 표현하도록 fill=ageg
# 지역별로 비교하기 쉽도록 coord_flip() : 그래프 우측 회전
ggplot(data=region_ageg, aes(x = region, y=pct, fill = ageg))+
geom_col() +
coord_filp()
# 2. 그래프 만들기
# 연령대 비율 막대를 서로 다른 색으로 표현하도록 fill=ageg
# 지역별로 비교하기 쉽도록 coord_flip() : 그래프 우측 회전
ggplot(data=region_ageg, aes(x = region, y=pct, fill = ageg))+
geom_col() +
coord_flip()
# 3. 노년층 비율 높은 순으로 막대 정렬하기
# 먼저 노년층 비율 순으로 지역명이 정렬된 변수를 만들어야 한다.
# 앞에서 만든 표를 노년층 비율 순으로 정렬한 후 지역명만 추출해 변수를 만든다.
list_order_old <- region_ageg %>%
filter(ageg=='old') %>%
arrange(pct)
list_order_old
# 지역명 순서 변수 만들기
order <- list_order_old$region
order
ggplot(data = region_ageg, aes(x= ageg, y =pct, fill = ageg)) +
geom_col() +
coord_flip() +
scale_x_discrete(limits = order)
ggplot(data = region_ageg, aes(x= ageg, y =pct, fill = ageg)) +
geom_col() +
coord_flip() +
scale_x_discrete(limits = order)
ggplot(data = region_ageg, aes(x= region, y =pct, fill = ageg)) +
geom_col() +
coord_flip() +
scale_x_discrete(limits = order)
class(region_ageg$ageg)
levels(region_ageg)
levels(region_ageg$ageg)
# factor()를 이용해 ageg 변수를 factor 타입으로 변환, level 파라미터를 이용해 순서 지정
region_ageg$ageg <- factor(region_ageg$ageg, level = c("old","middle","young"))
class(region_ageg$ageg)
levels(region_ageg$ageg)
ggplot(data = region_ageg, aes(x= region, y =pct, fill = ageg)) +
geom_col() +
coord_flip() +
scale_x_discrete(limits = order)
# 1. 자바와 rJava 패키지 설치
install.packages('multilinguer')
library(multilinguer)
install_jdk()
library(multilinguer)
search()
download.file(url = "https://repo1.maven.org/maven2/org/scala-lang/scala-library/2.11.8/scala-library-2.11.8.jar",
destfile = paste0(.libPaths()[1], "/KoNLP/Java/scala-library-2.11.8.jar"))
library(KoNLP)
extractNoun("대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.")
extractNoun("대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.")
search()
# 4. 형태소 사전 설정하기
useNIADic()
# 5. 데이터 준비하기
getwd()
txt <- readLines('hiphop.txt')
head(txt)
# 5. 데이터 준비하기
getwd()
txt <- readLines('hiphop.txt')
head(txt)
# 5. 데이터 준비하기
getwd()
txt <- readLines('hiphop.txt')
txt <- readLines('hiphop.txt')
head(txt)
extractNoun("대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.")
txt <- readLines('hiphop.txt')
head(txt)
txt <- readLines("hiphop.txt")
head(txt)
txt <- readLines("./hiphop.txt")
head(txt)
txt <- readLines("./hiphop.txt")
txt <- readLines("hiphop.txt", encoding = 'EUC-KR')
head(txt)
txt <- readLines("hiphop.txt")
head(txt)
txt <- readLines("hiphop.txt")
head(txt)
txt <- readLines("hiphop.txt")
head(txt)
# 6. 특수문자 제거하기
install.packages('stringr')
library(stringr)
# 특수문자 제거
txt <- str_replace_all(txt, '\\W',' ')
# 가장 많이 사용된 단어 알아보기
# 1. 명사 추출하기
library(KoNLP)
extractNoun("대한민국의 영토는 한반도와 그 부속도서로 한다")
# 가사에서 명사 추출
nouns <- extractNoun(txt)
# 추출한 명사 list를 문자열 벡터로 변환, 단어별 빈도표 생성
wordcount <- table(unlist(nouns))
# 데이터 프레임으로 변환
df_word <- as.data.frame(wordcount, stringsAsFactors = F)
# 추출한 명사 list를 문자열 벡터로 변환, 단어별 빈도표 생성
wordcount <- table(unlist(nouns))
wordcount
df_word <- rename(df_word,
word = Var1,
freq = Freq)
# 가장 많이 사용된 단어 알아보기
# 1. 명사 추출하기
library(stringr)
df_word <- rename(df_word,
word = Var1,
freq = Freq)
library(dplyr)
df_word <- rename(df_word,
word = Var1,
freq = Freq)
# 3. 자주 사용된 단어 빈도표 만들기
# 한 글자로된 단어는 의미없는 경우가 많기에 nchar() 로 두 글자 이상으로 된 단어만 추출
df_word %>% filter(nchar(word) >= 2)
df_word <- filter(df_word, nchar(word) >= 2)
df_word
top_20 <- df_word %>%
arrange(desc(freq)) %>%
head(20)
top_20
# 워드 클라우드 만들기
# 단어의 빈도를 구름모양으로 표현한 그래프
# 어떤 단어가 얼마나 많이 사용됐는지 한눈에 파악
# 1. 패키지 준비하기
install.packages('wordcloud')
library(wordcloud)
library(RColorBrewer)
# 2. 단어 색상 목록 만들기
pal <- brewer.pal(8, 'Dark2') # Dark2 색상 목록에서 8개 색상 추출
# 3. 난수 고정하기
# wordcloud()는 함수를 실행할 때마다 난수를 이용해 매번 다른 모양을 생성
# 항상 동일한 워드 클라우드 생성되도록 set.seed()로 난수 고정
set.seed(1234)
# 4. 워드 클라우드 만들기
wordcloud(words = df_word$word, # 단어
freq = df_word$freq, # 빈도
min.freq = 2, # 최소 단어 빈도
max.words = 200 #표현 단어 수
random.order = F, # 고빈도 단어 중앙 배치
# 4. 워드 클라우드 만들기
wordcloud(words = df_word$word, # 단어
freq = df_word$freq, # 빈도
min.freq = 2, # 최소 단어 빈도
max.words = 200, #표현 단어 수
random.order = F, # 고빈도 단어 중앙 배치
rot.per = .1, # 회전 단어 비율
scale = c(4, 0.3), # 단어 크기 범위
colors = pal) # 색상 목록
# 4. 워드 클라우드 만들기
wordcloud(words = df_word$word, # 단어
freq = df_word$freq, # 빈도
min.freq = 2, # 최소 단어 빈도
max.words = 200, #표현 단어 수
random.order = F, # 고빈도 단어 중앙 배치
rot.per = .1, # 회전 단어 비율
scale = c(4, 0.3), # 단어 크기 범위
colors = pal) # 색상 목록
# 4. 워드 클라우드 만들기
wordcloud(words = df_word$word, # 단어
freq = df_word$freq, # 빈도
min.freq = 2, # 최소 단어 빈도
max.words = 200, #표현 단어 수
random.order = F, # 고빈도 단어 중앙 배치
rot.per = .1, # 회전 단어 비율
scale = c(4, 0.3), # 단어 크기 범위
colors = pal) # 색상 목록
# 3. 난수 고정하기
# wordcloud()는 함수를 실행할 때마다 난수를 이용해 매번 다른 모양을 생성
# 항상 동일한 워드 클라우드 생성되도록 set.seed()로 난수 고정
set.seed(1234)
# 4. 워드 클라우드 만들기
wordcloud(words = df_word$word, # 단어
freq = df_word$freq, # 빈도
min.freq = 2, # 최소 단어 빈도
max.words = 200, #표현 단어 수
random.order = F, # 고빈도 단어 중앙 배치
rot.per = .1, # 회전 단어 비율
scale = c(4, 0.3), # 단어 크기 범위
colors = pal) # 색상 목록
# 5. 단어 색상 바꾸기
pal <- brewer.pal(9, 'Blues')[5:9] # 색상 목록 생성
set.seed(1233)
wordcloud(words = df_word$word, # 단어
freq = df_word$freq, # 빈도
min.freq = 2, # 최소 단어 빈도
max.words = 200, #표현 단어 수
random.order = F, # 고빈도 단어 중앙 배치
rot.per = .1, # 회전 단어 비율
scale = c(4, 0.3), # 단어 크기 범위
colors = pal) # 색상 목록
set.seed(12345)
wordcloud(words = df_word$word, # 단어
freq = df_word$freq, # 빈도
min.freq = 2, # 최소 단어 빈도
max.words = 200, #표현 단어 수
random.order = F, # 고빈도 단어 중앙 배치
rot.per = .1, # 회전 단어 비율
scale = c(4, 0.3), # 단어 크기 범위
colors = pal) # 색상 목록
set.seed(1234)
wordcloud(words = df_word$word, # 단어
freq = df_word$freq, # 빈도
min.freq = 2, # 최소 단어 빈도
max.words = 200, #표현 단어 수
random.order = F, # 고빈도 단어 중앙 배치
rot.per = .1, # 회전 단어 비율
scale = c(4, 0.3), # 단어 크기 범위
colors = pal) # 색상 목록
# 1. 데이터 준비하기
twitter <- read.csv('twitter.csv',
header = T,
fileEncoding = "UTF-8")
table(twitter)
head(twitter)
colnames(twitter)
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
# 특수문자 제거
twitter$tw <- str_replace_all(twitter$tw, '\\W', ' ')
head(twitter$tw)
# 2. 단어 빈도표 만들기
# 트윗에서 명사추출
nouns <- extractNoun(twitter$tw)
nouns
# 추출한 명사 list를 문자열 벡터로 변환, 단어별 빈도표 생성
wordcount <- table(unlist(nouns))
head(wordcount)
wordcount
# 데이터 프레임으로 변환
df_word <- as.data.frame(wordcount)
df_word
df_word <- rename(df_word,
word = Var1,
freq = Freq)
# 두글자 이상 단어만 추출
df_word <- filter(df_word, nchar(word) >= 2)
# 두글자 이상 단어만 추출
df_word <- filter(df_word, nchar(word) >= 2)
df_word <- rename(df_word,
word = Var1,
freq = Freq)
# 두글자 이상 단어만 추출
df_word <- filter(df_word, nchar(word) >= 2)
# 2. 단어 빈도표 만들기
# 트윗에서 명사추출
nouns <- extractNoun(twitter$tw)
# 추출한 명사 list를 문자열 벡터로 변환, 단어별 빈도표 생성
wordcount <- table(unlist(nouns))
# 데이터 프레임으로 변환
df_word <- as.data.frame(wordcount)
df_word <- rename(df_word,
word = Var1,
freq = Freq)
# 두글자 이상 단어만 추출
df_word <- filter(df_word, nchar(word) >= 2)
View(df_word)
# 1. 데이터 준비하기
twitter <- read.csv('twitter.csv',
header = T,
fileEncoding = "UTF-8")
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
# 특수문자 제거
twitter$tw <- str_replace_all(twitter$tw, '\\W', ' ')
# 2. 단어 빈도표 만들기
# 트윗에서 명사추출
nouns <- extractNoun(twitter$tw)
# 추출한 명사 list를 문자열 벡터로 변환, 단어별 빈도표 생성
wordcount <- table(unlist(nouns))
# 데이터 프레임으로 변환
df_word <- as.data.frame(wordcount)
df_word <- rename(df_word,
word = Var1,
freq = Freq)
# 두글자 이상 단어만 추출
df_word <- filter(df_word, nchar(word) >= 2)
# 두글자 이상 단어만 추출
library(stringr)
df_word <- filter(df_word, nchar(word) >= 2)
df_word <- filter(df_word, nchar(word) >= 2)
df_word <- filter(df_word, str_length(word) >= 2)
# 상위 20개 추출
top20 <- df_word %>%
arrange(desc(freq)) %>%
head(20)
top20
library(ggplot2)
order <- arrange(top20, freq)$word # 빈도 순서 변수 생성
order
ggplot(data = top20, aes(x = word, y = freq)) +
ylim(0, 2500) +
geom_col() +
coord_flip() +
scale_x_discrete(limit = order) + # 빈도순 막대 정렬
geom_text(aes(label = freq), hjust = 0.1) # 빈도 표시
